hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

data:
  gen_batch_size: ${data.train_batch_size}

reward_model:
  reward_manager: dapo
  use_xverify: True
  overlong_buffer: 
    enable: False # We try to avoid forgetting to set enable
    len: 0
    penalty_factor: 0.0
    log: False

custom_reward_function:
  path: null
  name: compute_score

algorithm:
  filter_groups:
    enable: False # We try to avoid forgetting to set enable
    metric: null # acc / score / seq_reward / seq_final_reward / ...
    max_num_gen_batches: 0 # Non-positive values mean no upper limit
    confidence_upper_bound: 1.0
    confidence_lower_bound: 0.0

# trainer:
#   balance_batch: True
#   total_epochs: 30
#   total_training_steps: null
#   project_name: verl_examples
#   experiment_name: gsm8k
#   logger: [ 'console', 'wandb' ]
#   log_val_generations: 0
#   nnodes: 1
#   n_gpus_per_node: 8
#   save_freq: -1
#   # auto: find the last ckpt to resume. If can't find, start from scratch
#   resume_mode: auto # or disable or resume_path if resume_from_path is set
#   resume_from_path: null
#   val_before_train: True
#   test_freq: -1
#   critic_warmup: 0
#   default_hdfs_dir: null
#   remove_previous_ckpt_in_save: False
#   del_local_ckpt_after_load: False
#   default_local_dir: checkpoints/${trainer.project_name}/${trainer.experiment_name}
#   max_actor_ckpt_to_keep: null
#   max_critic_ckpt_to_keep: null
#   # The timeout for ray worker group to wait for the register center to be ready
#   ray_wait_register_center_timeout: 300
